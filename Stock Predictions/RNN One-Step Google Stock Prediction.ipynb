{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "lr = 0.1\n",
    "T = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-28</th>\n",
       "      <td>950.659973</td>\n",
       "      <td>963.239990</td>\n",
       "      <td>936.159973</td>\n",
       "      <td>961.010010</td>\n",
       "      <td>961.010010</td>\n",
       "      <td>2745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-29</th>\n",
       "      <td>951.349976</td>\n",
       "      <td>951.659973</td>\n",
       "      <td>929.599976</td>\n",
       "      <td>937.820007</td>\n",
       "      <td>937.820007</td>\n",
       "      <td>3206700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>943.989990</td>\n",
       "      <td>945.000000</td>\n",
       "      <td>929.609985</td>\n",
       "      <td>929.679993</td>\n",
       "      <td>929.679993</td>\n",
       "      <td>2287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03</th>\n",
       "      <td>933.219971</td>\n",
       "      <td>934.239990</td>\n",
       "      <td>915.309998</td>\n",
       "      <td>919.460022</td>\n",
       "      <td>919.460022</td>\n",
       "      <td>1694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-05</th>\n",
       "      <td>924.200012</td>\n",
       "      <td>936.289978</td>\n",
       "      <td>918.630005</td>\n",
       "      <td>932.260010</td>\n",
       "      <td>932.260010</td>\n",
       "      <td>2094100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2017-06-28  950.659973  963.239990  936.159973  961.010010  961.010010   \n",
       "2017-06-29  951.349976  951.659973  929.599976  937.820007  937.820007   \n",
       "2017-06-30  943.989990  945.000000  929.609985  929.679993  929.679993   \n",
       "2017-07-03  933.219971  934.239990  915.309998  919.460022  919.460022   \n",
       "2017-07-05  924.200012  936.289978  918.630005  932.260010  932.260010   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2017-06-28  2745600  \n",
       "2017-06-29  3206700  \n",
       "2017-06-30  2287700  \n",
       "2017-07-03  1694800  \n",
       "2017-07-05  2094100  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../data/GOOGL.csv\", header=0, index_col=0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1258, 1)\n",
      "Outputs shape: (1258, 1)\n"
     ]
    }
   ],
   "source": [
    "# X = df.iloc[:, :]\n",
    "X = np.reshape(np.array(df.iloc[:, 0]), (-1, 1))\n",
    "\n",
    "Y = np.reshape(np.array(df.iloc[:, 0]), (-1, 1))\n",
    "\n",
    "print(f\"Inputs shape: {X.shape}\")\n",
    "print(f\"Outputs shape: {Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "N_train = X.shape[0] // 5 * 4\n",
    "N_tot = X.shape[0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# we scale by looking only on the training data, thus test data is not considered\n",
    "scaler.fit(X[:N_train])\n",
    "# but we still apply scaling on all the data since we need to be able to make predictions\n",
    "X = scaler.transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# we scale by looking only on the training data, thus test data is not considered\n",
    "scaler.fit(Y[:N_train])\n",
    "# but we still apply scaling on all the data since we need to be able to make predictions\n",
    "Y = scaler.transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.zeros((N_tot - T, T, X.shape[1]))\n",
    "targets = np.zeros((N_tot - T, 1))\n",
    "\n",
    "for t in range(N_tot - T):\n",
    "    inputs[t] = X[t : t + T]\n",
    "    targets[t] = Y[t+T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: torch.Size([1004, 15, 1]) for Inputs and torch.Size([1004, 1]) for Targets\n",
      "Test shapes: torch.Size([239, 15, 1]) for Inputs and torch.Size([239, 1]) for Targets\n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.from_numpy(inputs[:N_train].astype(np.float32)).to(device)\n",
    "train_targets = torch.from_numpy(targets[:N_train].astype(np.float32)).to(device)\n",
    "test_inputs = torch.from_numpy(inputs[N_train:].astype(np.float32)).to(device)\n",
    "test_targets = torch.from_numpy(targets[N_train:].astype(np.float32)).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Train shapes: {train_inputs.shape} for Inputs and {train_targets.shape} for Targets\"\n",
    ")\n",
    "print(\n",
    "    f\"Test shapes: {test_inputs.shape} for Inputs and {test_targets.shape} for Targets\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, outputs_size, device=\"cpu\"):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.D = input_size\n",
    "        self.M = hidden_size\n",
    "        self.L = num_layers\n",
    "        self.K = outputs_size\n",
    "\n",
    "        self.rnn_layer = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.M, self.K)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        h0 = torch.zeros((self.L, inputs.size(0), self.M)).to(self.device)\n",
    "        c0 = torch.zeros((self.L, inputs.size(0), self.M)).to(self.device)\n",
    "\n",
    "        outputs, _ = self.rnn_layer(inputs, (h0, c0))\n",
    "        outputs = self.fc(outputs[:, -1, :])\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn_layer): LSTM(1, 10, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(\n",
    "    input_size=X.shape[1],\n",
    "    outputs_size=Y.shape[1],\n",
    "    hidden_size=10,\n",
    "    num_layers=2,\n",
    "    device=device,\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_inputs,\n",
    "    train_targets,\n",
    "    test_inputs,\n",
    "    test_targets,\n",
    "    n_epochs=200,\n",
    "):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    test_losses = np.zeros(n_epochs)\n",
    "\n",
    "    for it in range(n_epochs):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs)\n",
    "        loss = criterion(outputs, train_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses[it] = loss.item()\n",
    "        test_losses[it] = criterion(model(test_inputs), test_targets).item()\n",
    "\n",
    "        print(\n",
    "            f\"Iteration: {it+1:2.0f}/{n_epochs} \\t Train Loss: {train_losses[it]:.4f} \\t Test Loss: {test_losses[it]:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/1000 \t Train Loss: 1.1799 \t Test Loss: 9.1049\n",
      "Iteration:  2/1000 \t Train Loss: 0.9546 \t Test Loss: 9.6666\n",
      "Iteration:  3/1000 \t Train Loss: 0.7418 \t Test Loss: 5.6438\n",
      "Iteration:  4/1000 \t Train Loss: 0.3187 \t Test Loss: 3.2045\n",
      "Iteration:  5/1000 \t Train Loss: 0.3090 \t Test Loss: 2.4262\n",
      "Iteration:  6/1000 \t Train Loss: 0.3035 \t Test Loss: 3.4402\n",
      "Iteration:  7/1000 \t Train Loss: 0.2062 \t Test Loss: 3.8233\n",
      "Iteration:  8/1000 \t Train Loss: 0.1746 \t Test Loss: 3.1148\n",
      "Iteration:  9/1000 \t Train Loss: 0.1111 \t Test Loss: 2.3804\n",
      "Iteration: 10/1000 \t Train Loss: 0.0889 \t Test Loss: 1.9067\n",
      "Iteration: 11/1000 \t Train Loss: 0.0695 \t Test Loss: 1.5773\n",
      "Iteration: 12/1000 \t Train Loss: 0.0772 \t Test Loss: 1.2142\n",
      "Iteration: 13/1000 \t Train Loss: 0.0327 \t Test Loss: 0.9035\n",
      "Iteration: 14/1000 \t Train Loss: 0.0295 \t Test Loss: 0.7298\n",
      "Iteration: 15/1000 \t Train Loss: 0.0457 \t Test Loss: 0.6751\n",
      "Iteration: 16/1000 \t Train Loss: 0.0533 \t Test Loss: 0.4239\n",
      "Iteration: 17/1000 \t Train Loss: 0.0295 \t Test Loss: 0.3409\n",
      "Iteration: 18/1000 \t Train Loss: 0.0244 \t Test Loss: 0.4013\n",
      "Iteration: 19/1000 \t Train Loss: 0.0290 \t Test Loss: 0.3955\n",
      "Iteration: 20/1000 \t Train Loss: 0.0345 \t Test Loss: 0.2341\n",
      "Iteration: 21/1000 \t Train Loss: 0.0232 \t Test Loss: 0.1770\n",
      "Iteration: 22/1000 \t Train Loss: 0.0160 \t Test Loss: 0.1971\n",
      "Iteration: 23/1000 \t Train Loss: 0.0131 \t Test Loss: 0.2517\n",
      "Iteration: 24/1000 \t Train Loss: 0.0224 \t Test Loss: 0.1720\n",
      "Iteration: 25/1000 \t Train Loss: 0.0188 \t Test Loss: 0.1301\n",
      "Iteration: 26/1000 \t Train Loss: 0.0149 \t Test Loss: 0.1478\n",
      "Iteration: 27/1000 \t Train Loss: 0.0099 \t Test Loss: 0.2421\n",
      "Iteration: 28/1000 \t Train Loss: 0.0108 \t Test Loss: 0.3233\n",
      "Iteration: 29/1000 \t Train Loss: 0.0119 \t Test Loss: 0.3329\n",
      "Iteration: 30/1000 \t Train Loss: 0.0103 \t Test Loss: 0.3315\n",
      "Iteration: 31/1000 \t Train Loss: 0.0097 \t Test Loss: 0.3470\n",
      "Iteration: 32/1000 \t Train Loss: 0.0080 \t Test Loss: 0.3482\n",
      "Iteration: 33/1000 \t Train Loss: 0.0086 \t Test Loss: 0.2766\n",
      "Iteration: 34/1000 \t Train Loss: 0.0090 \t Test Loss: 0.1701\n",
      "Iteration: 35/1000 \t Train Loss: 0.0073 \t Test Loss: 0.1215\n",
      "Iteration: 36/1000 \t Train Loss: 0.0074 \t Test Loss: 0.1212\n",
      "Iteration: 37/1000 \t Train Loss: 0.0061 \t Test Loss: 0.1522\n",
      "Iteration: 38/1000 \t Train Loss: 0.0069 \t Test Loss: 0.1569\n",
      "Iteration: 39/1000 \t Train Loss: 0.0072 \t Test Loss: 0.1252\n",
      "Iteration: 40/1000 \t Train Loss: 0.0066 \t Test Loss: 0.1090\n",
      "Iteration: 41/1000 \t Train Loss: 0.0066 \t Test Loss: 0.1154\n",
      "Iteration: 42/1000 \t Train Loss: 0.0056 \t Test Loss: 0.1237\n",
      "Iteration: 43/1000 \t Train Loss: 0.0061 \t Test Loss: 0.1086\n",
      "Iteration: 44/1000 \t Train Loss: 0.0060 \t Test Loss: 0.0962\n",
      "Iteration: 45/1000 \t Train Loss: 0.0060 \t Test Loss: 0.1063\n",
      "Iteration: 46/1000 \t Train Loss: 0.0055 \t Test Loss: 0.1438\n",
      "Iteration: 47/1000 \t Train Loss: 0.0051 \t Test Loss: 0.1796\n",
      "Iteration: 48/1000 \t Train Loss: 0.0057 \t Test Loss: 0.1737\n",
      "Iteration: 49/1000 \t Train Loss: 0.0057 \t Test Loss: 0.1484\n",
      "Iteration: 50/1000 \t Train Loss: 0.0054 \t Test Loss: 0.1348\n",
      "Iteration: 51/1000 \t Train Loss: 0.0050 \t Test Loss: 0.1325\n",
      "Iteration: 52/1000 \t Train Loss: 0.0050 \t Test Loss: 0.1271\n",
      "Iteration: 53/1000 \t Train Loss: 0.0054 \t Test Loss: 0.1178\n",
      "Iteration: 54/1000 \t Train Loss: 0.0052 \t Test Loss: 0.1191\n",
      "Iteration: 55/1000 \t Train Loss: 0.0050 \t Test Loss: 0.1378\n",
      "Iteration: 56/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1630\n",
      "Iteration: 57/1000 \t Train Loss: 0.0051 \t Test Loss: 0.1700\n",
      "Iteration: 58/1000 \t Train Loss: 0.0051 \t Test Loss: 0.1594\n",
      "Iteration: 59/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1524\n",
      "Iteration: 60/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1568\n",
      "Iteration: 61/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1639\n",
      "Iteration: 62/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1657\n",
      "Iteration: 63/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1689\n",
      "Iteration: 64/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1814\n",
      "Iteration: 65/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1961\n",
      "Iteration: 66/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1969\n",
      "Iteration: 67/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1846\n",
      "Iteration: 68/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1754\n",
      "Iteration: 69/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1755\n",
      "Iteration: 70/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1768\n",
      "Iteration: 71/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1729\n",
      "Iteration: 72/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1711\n",
      "Iteration: 73/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1771\n",
      "Iteration: 74/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1840\n",
      "Iteration: 75/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1832\n",
      "Iteration: 76/1000 \t Train Loss: 0.0047 \t Test Loss: 0.1799\n",
      "Iteration: 77/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1821\n",
      "Iteration: 78/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1860\n",
      "Iteration: 79/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1840\n",
      "Iteration: 80/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1800\n",
      "Iteration: 81/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1817\n",
      "Iteration: 82/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1860\n",
      "Iteration: 83/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1856\n",
      "Iteration: 84/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1826\n",
      "Iteration: 85/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1828\n",
      "Iteration: 86/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1834\n",
      "Iteration: 87/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1794\n",
      "Iteration: 88/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1752\n",
      "Iteration: 89/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1766\n",
      "Iteration: 90/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1803\n",
      "Iteration: 91/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1809\n",
      "Iteration: 92/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1806\n",
      "Iteration: 93/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1819\n",
      "Iteration: 94/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1810\n",
      "Iteration: 95/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1762\n",
      "Iteration: 96/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1728\n",
      "Iteration: 97/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1734\n",
      "Iteration: 98/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1736\n",
      "Iteration: 99/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1715\n",
      "Iteration: 100/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1699\n",
      "Iteration: 101/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1688\n",
      "Iteration: 102/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1653\n",
      "Iteration: 103/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1611\n",
      "Iteration: 104/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1600\n",
      "Iteration: 105/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1603\n",
      "Iteration: 106/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1590\n",
      "Iteration: 107/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1575\n",
      "Iteration: 108/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1569\n",
      "Iteration: 109/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1550\n",
      "Iteration: 110/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1517\n",
      "Iteration: 111/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1496\n",
      "Iteration: 112/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1489\n",
      "Iteration: 113/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1471\n",
      "Iteration: 114/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1452\n",
      "Iteration: 115/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1443\n",
      "Iteration: 116/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1432\n",
      "Iteration: 117/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1411\n",
      "Iteration: 118/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1397\n",
      "Iteration: 119/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1392\n",
      "Iteration: 120/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1380\n",
      "Iteration: 121/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1367\n",
      "Iteration: 122/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1365\n",
      "Iteration: 123/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1360\n",
      "Iteration: 124/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1347\n",
      "Iteration: 125/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1337\n",
      "Iteration: 126/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1330\n",
      "Iteration: 127/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1316\n",
      "Iteration: 128/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1306\n",
      "Iteration: 129/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1304\n",
      "Iteration: 130/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1299\n",
      "Iteration: 131/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1291\n",
      "Iteration: 132/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1285\n",
      "Iteration: 133/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1278\n",
      "Iteration: 134/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1268\n",
      "Iteration: 135/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1262\n",
      "Iteration: 136/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1261\n",
      "Iteration: 137/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1255\n",
      "Iteration: 138/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1248\n",
      "Iteration: 139/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1242\n",
      "Iteration: 140/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1234\n",
      "Iteration: 141/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1224\n",
      "Iteration: 142/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1220\n",
      "Iteration: 143/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1216\n",
      "Iteration: 144/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1210\n",
      "Iteration: 145/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1206\n",
      "Iteration: 146/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1201\n",
      "Iteration: 147/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1194\n",
      "Iteration: 148/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1189\n",
      "Iteration: 149/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1186\n",
      "Iteration: 150/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1180\n",
      "Iteration: 151/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1176\n",
      "Iteration: 152/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1172\n",
      "Iteration: 153/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1166\n",
      "Iteration: 154/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1161\n",
      "Iteration: 155/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1157\n",
      "Iteration: 156/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1152\n",
      "Iteration: 157/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1147\n",
      "Iteration: 158/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1144\n",
      "Iteration: 159/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1140\n",
      "Iteration: 160/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1135\n",
      "Iteration: 161/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1131\n",
      "Iteration: 162/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1127\n",
      "Iteration: 163/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1121\n",
      "Iteration: 164/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1118\n",
      "Iteration: 165/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1114\n",
      "Iteration: 166/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1109\n",
      "Iteration: 167/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1105\n",
      "Iteration: 168/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1100\n",
      "Iteration: 169/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1095\n",
      "Iteration: 170/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1091\n",
      "Iteration: 171/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1087\n",
      "Iteration: 172/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1083\n",
      "Iteration: 173/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1079\n",
      "Iteration: 174/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1075\n",
      "Iteration: 175/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1070\n",
      "Iteration: 176/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1066\n",
      "Iteration: 177/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1061\n",
      "Iteration: 178/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1057\n",
      "Iteration: 179/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1053\n",
      "Iteration: 180/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1049\n",
      "Iteration: 181/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1045\n",
      "Iteration: 182/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1041\n",
      "Iteration: 183/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1037\n",
      "Iteration: 184/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1033\n",
      "Iteration: 185/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1029\n",
      "Iteration: 186/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1025\n",
      "Iteration: 187/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1021\n",
      "Iteration: 188/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1018\n",
      "Iteration: 189/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1014\n",
      "Iteration: 190/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1010\n",
      "Iteration: 191/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1006\n",
      "Iteration: 192/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1002\n",
      "Iteration: 193/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0999\n",
      "Iteration: 194/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0995\n",
      "Iteration: 195/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0991\n",
      "Iteration: 196/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0988\n",
      "Iteration: 197/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0984\n",
      "Iteration: 198/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0981\n",
      "Iteration: 199/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0977\n",
      "Iteration: 200/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0974\n",
      "Iteration: 201/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0970\n",
      "Iteration: 202/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0967\n",
      "Iteration: 203/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0963\n",
      "Iteration: 204/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0960\n",
      "Iteration: 205/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0956\n",
      "Iteration: 206/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0953\n",
      "Iteration: 207/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0950\n",
      "Iteration: 208/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0946\n",
      "Iteration: 209/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0943\n",
      "Iteration: 210/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0940\n",
      "Iteration: 211/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0937\n",
      "Iteration: 212/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0934\n",
      "Iteration: 213/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0930\n",
      "Iteration: 214/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0927\n",
      "Iteration: 215/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0924\n",
      "Iteration: 216/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0921\n",
      "Iteration: 217/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0918\n",
      "Iteration: 218/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0915\n",
      "Iteration: 219/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0912\n",
      "Iteration: 220/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0909\n",
      "Iteration: 221/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0906\n",
      "Iteration: 222/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0903\n",
      "Iteration: 223/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0900\n",
      "Iteration: 224/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0897\n",
      "Iteration: 225/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0894\n",
      "Iteration: 226/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0891\n",
      "Iteration: 227/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0888\n",
      "Iteration: 228/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0885\n",
      "Iteration: 229/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0883\n",
      "Iteration: 230/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0880\n",
      "Iteration: 231/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0877\n",
      "Iteration: 232/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0874\n",
      "Iteration: 233/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0872\n",
      "Iteration: 234/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0869\n",
      "Iteration: 235/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0866\n",
      "Iteration: 236/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0863\n",
      "Iteration: 237/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0861\n",
      "Iteration: 238/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0858\n",
      "Iteration: 239/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0856\n",
      "Iteration: 240/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0853\n",
      "Iteration: 241/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0850\n",
      "Iteration: 242/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0848\n",
      "Iteration: 243/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0845\n",
      "Iteration: 244/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0843\n",
      "Iteration: 245/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0840\n",
      "Iteration: 246/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0838\n",
      "Iteration: 247/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0835\n",
      "Iteration: 248/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0833\n",
      "Iteration: 249/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0830\n",
      "Iteration: 250/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0828\n",
      "Iteration: 251/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0826\n",
      "Iteration: 252/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0823\n",
      "Iteration: 253/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0821\n",
      "Iteration: 254/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0819\n",
      "Iteration: 255/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0816\n",
      "Iteration: 256/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0814\n",
      "Iteration: 257/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0812\n",
      "Iteration: 258/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0809\n",
      "Iteration: 259/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0807\n",
      "Iteration: 260/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0805\n",
      "Iteration: 261/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0803\n",
      "Iteration: 262/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0801\n",
      "Iteration: 263/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0798\n",
      "Iteration: 264/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0796\n",
      "Iteration: 265/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0794\n",
      "Iteration: 266/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0792\n",
      "Iteration: 267/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0790\n",
      "Iteration: 268/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0788\n",
      "Iteration: 269/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0786\n",
      "Iteration: 270/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0784\n",
      "Iteration: 271/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0782\n",
      "Iteration: 272/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0780\n",
      "Iteration: 273/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0778\n",
      "Iteration: 274/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0776\n",
      "Iteration: 275/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0774\n",
      "Iteration: 276/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0772\n",
      "Iteration: 277/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0770\n",
      "Iteration: 278/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0768\n",
      "Iteration: 279/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0766\n",
      "Iteration: 280/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0764\n",
      "Iteration: 281/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0762\n",
      "Iteration: 282/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0760\n",
      "Iteration: 283/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0758\n",
      "Iteration: 284/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0756\n",
      "Iteration: 285/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0754\n",
      "Iteration: 286/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0753\n",
      "Iteration: 287/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0751\n",
      "Iteration: 288/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0749\n",
      "Iteration: 289/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0747\n",
      "Iteration: 290/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0746\n",
      "Iteration: 291/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0743\n",
      "Iteration: 292/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0743\n",
      "Iteration: 293/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0739\n",
      "Iteration: 294/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0741\n",
      "Iteration: 295/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0733\n",
      "Iteration: 296/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0741\n",
      "Iteration: 297/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0725\n",
      "Iteration: 298/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0746\n",
      "Iteration: 299/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0710\n",
      "Iteration: 300/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0766\n",
      "Iteration: 301/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0682\n",
      "Iteration: 302/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0839\n",
      "Iteration: 303/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0643\n",
      "Iteration: 304/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1135\n",
      "Iteration: 305/1000 \t Train Loss: 0.0057 \t Test Loss: 0.0653\n",
      "Iteration: 306/1000 \t Train Loss: 0.0067 \t Test Loss: 0.2040\n",
      "Iteration: 307/1000 \t Train Loss: 0.0092 \t Test Loss: 0.0694\n",
      "Iteration: 308/1000 \t Train Loss: 0.0070 \t Test Loss: 0.1333\n",
      "Iteration: 309/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1347\n",
      "Iteration: 310/1000 \t Train Loss: 0.0050 \t Test Loss: 0.0761\n",
      "Iteration: 311/1000 \t Train Loss: 0.0062 \t Test Loss: 0.1615\n",
      "Iteration: 312/1000 \t Train Loss: 0.0056 \t Test Loss: 0.1205\n",
      "Iteration: 313/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0810\n",
      "Iteration: 314/1000 \t Train Loss: 0.0057 \t Test Loss: 0.1430\n",
      "Iteration: 315/1000 \t Train Loss: 0.0057 \t Test Loss: 0.0957\n",
      "Iteration: 316/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0764\n",
      "Iteration: 317/1000 \t Train Loss: 0.0054 \t Test Loss: 0.1415\n",
      "Iteration: 318/1000 \t Train Loss: 0.0055 \t Test Loss: 0.1065\n",
      "Iteration: 319/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0806\n",
      "Iteration: 320/1000 \t Train Loss: 0.0053 \t Test Loss: 0.1291\n",
      "Iteration: 321/1000 \t Train Loss: 0.0051 \t Test Loss: 0.1022\n",
      "Iteration: 322/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0755\n",
      "Iteration: 323/1000 \t Train Loss: 0.0053 \t Test Loss: 0.1181\n",
      "Iteration: 324/1000 \t Train Loss: 0.0048 \t Test Loss: 0.1110\n",
      "Iteration: 325/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0804\n",
      "Iteration: 326/1000 \t Train Loss: 0.0051 \t Test Loss: 0.1095\n",
      "Iteration: 327/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1125\n",
      "Iteration: 328/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0837\n",
      "Iteration: 329/1000 \t Train Loss: 0.0049 \t Test Loss: 0.1064\n",
      "Iteration: 330/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1247\n",
      "Iteration: 331/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0918\n",
      "Iteration: 332/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0922\n",
      "Iteration: 333/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1091\n",
      "Iteration: 334/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0899\n",
      "Iteration: 335/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0878\n",
      "Iteration: 336/1000 \t Train Loss: 0.0045 \t Test Loss: 0.1084\n",
      "Iteration: 337/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0952\n",
      "Iteration: 338/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0837\n",
      "Iteration: 339/1000 \t Train Loss: 0.0046 \t Test Loss: 0.1001\n",
      "Iteration: 340/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0982\n",
      "Iteration: 341/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0843\n",
      "Iteration: 342/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0932\n",
      "Iteration: 343/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0933\n",
      "Iteration: 344/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0773\n",
      "Iteration: 345/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0798\n",
      "Iteration: 346/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0844\n",
      "Iteration: 347/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0739\n",
      "Iteration: 348/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0745\n",
      "Iteration: 349/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0801\n",
      "Iteration: 350/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0719\n",
      "Iteration: 351/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0705\n",
      "Iteration: 352/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0773\n",
      "Iteration: 353/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0728\n",
      "Iteration: 354/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0696\n",
      "Iteration: 355/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0741\n",
      "Iteration: 356/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0706\n",
      "Iteration: 357/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0676\n",
      "Iteration: 358/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0724\n",
      "Iteration: 359/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0709\n",
      "Iteration: 360/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0668\n",
      "Iteration: 361/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0695\n",
      "Iteration: 362/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0688\n",
      "Iteration: 363/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0652\n",
      "Iteration: 364/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0673\n",
      "Iteration: 365/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0670\n",
      "Iteration: 366/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0635\n",
      "Iteration: 367/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0648\n",
      "Iteration: 368/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0653\n",
      "Iteration: 369/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0629\n",
      "Iteration: 370/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 371/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0653\n",
      "Iteration: 372/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0630\n",
      "Iteration: 373/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0638\n",
      "Iteration: 374/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0647\n",
      "Iteration: 375/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0630\n",
      "Iteration: 376/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0637\n",
      "Iteration: 377/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0643\n",
      "Iteration: 378/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0626\n",
      "Iteration: 379/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0633\n",
      "Iteration: 380/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0643\n",
      "Iteration: 381/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0632\n",
      "Iteration: 382/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0637\n",
      "Iteration: 383/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0644\n",
      "Iteration: 384/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0633\n",
      "Iteration: 385/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0638\n",
      "Iteration: 386/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 387/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0636\n",
      "Iteration: 388/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0640\n",
      "Iteration: 389/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 390/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0637\n",
      "Iteration: 391/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 392/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0646\n",
      "Iteration: 393/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0639\n",
      "Iteration: 394/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0642\n",
      "Iteration: 395/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 396/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0639\n",
      "Iteration: 397/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0644\n",
      "Iteration: 398/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0646\n",
      "Iteration: 399/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 400/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 401/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0647\n",
      "Iteration: 402/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0644\n",
      "Iteration: 403/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0647\n",
      "Iteration: 404/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0647\n",
      "Iteration: 405/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0643\n",
      "Iteration: 406/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0646\n",
      "Iteration: 407/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0644\n",
      "Iteration: 408/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 409/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0644\n",
      "Iteration: 410/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 411/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0639\n",
      "Iteration: 412/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 413/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0638\n",
      "Iteration: 414/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0637\n",
      "Iteration: 415/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0638\n",
      "Iteration: 416/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0635\n",
      "Iteration: 417/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0633\n",
      "Iteration: 418/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0634\n",
      "Iteration: 419/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0631\n",
      "Iteration: 420/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0631\n",
      "Iteration: 421/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0630\n",
      "Iteration: 422/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0628\n",
      "Iteration: 423/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0627\n",
      "Iteration: 424/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0627\n",
      "Iteration: 425/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0624\n",
      "Iteration: 426/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0624\n",
      "Iteration: 427/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0622\n",
      "Iteration: 428/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0620\n",
      "Iteration: 429/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0620\n",
      "Iteration: 430/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0618\n",
      "Iteration: 431/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0616\n",
      "Iteration: 432/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0616\n",
      "Iteration: 433/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0614\n",
      "Iteration: 434/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0613\n",
      "Iteration: 435/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0612\n",
      "Iteration: 436/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0610\n",
      "Iteration: 437/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0609\n",
      "Iteration: 438/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0607\n",
      "Iteration: 439/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0606\n",
      "Iteration: 440/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0605\n",
      "Iteration: 441/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0603\n",
      "Iteration: 442/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0602\n",
      "Iteration: 443/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0601\n",
      "Iteration: 444/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0599\n",
      "Iteration: 445/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0598\n",
      "Iteration: 446/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0597\n",
      "Iteration: 447/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0595\n",
      "Iteration: 448/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0594\n",
      "Iteration: 449/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0593\n",
      "Iteration: 450/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0592\n",
      "Iteration: 451/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0591\n",
      "Iteration: 452/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0589\n",
      "Iteration: 453/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0587\n",
      "Iteration: 454/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0586\n",
      "Iteration: 455/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0585\n",
      "Iteration: 456/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0583\n",
      "Iteration: 457/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0582\n",
      "Iteration: 458/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0581\n",
      "Iteration: 459/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0579\n",
      "Iteration: 460/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0578\n",
      "Iteration: 461/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0577\n",
      "Iteration: 462/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0575\n",
      "Iteration: 463/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0574\n",
      "Iteration: 464/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0572\n",
      "Iteration: 465/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0571\n",
      "Iteration: 466/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0569\n",
      "Iteration: 467/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0568\n",
      "Iteration: 468/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0566\n",
      "Iteration: 469/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0565\n",
      "Iteration: 470/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0564\n",
      "Iteration: 471/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0562\n",
      "Iteration: 472/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0561\n",
      "Iteration: 473/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0559\n",
      "Iteration: 474/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0558\n",
      "Iteration: 475/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0556\n",
      "Iteration: 476/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0555\n",
      "Iteration: 477/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0553\n",
      "Iteration: 478/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0552\n",
      "Iteration: 479/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0550\n",
      "Iteration: 480/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0549\n",
      "Iteration: 481/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0547\n",
      "Iteration: 482/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0546\n",
      "Iteration: 483/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0544\n",
      "Iteration: 484/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0543\n",
      "Iteration: 485/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0541\n",
      "Iteration: 486/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0540\n",
      "Iteration: 487/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0538\n",
      "Iteration: 488/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0536\n",
      "Iteration: 489/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0535\n",
      "Iteration: 490/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0533\n",
      "Iteration: 491/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0532\n",
      "Iteration: 492/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0530\n",
      "Iteration: 493/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0529\n",
      "Iteration: 494/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0527\n",
      "Iteration: 495/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0526\n",
      "Iteration: 496/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0524\n",
      "Iteration: 497/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0523\n",
      "Iteration: 498/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0521\n",
      "Iteration: 499/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0520\n",
      "Iteration: 500/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0519\n",
      "Iteration: 501/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0517\n",
      "Iteration: 502/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0516\n",
      "Iteration: 503/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0514\n",
      "Iteration: 504/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0513\n",
      "Iteration: 505/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0511\n",
      "Iteration: 506/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0510\n",
      "Iteration: 507/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0508\n",
      "Iteration: 508/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0507\n",
      "Iteration: 509/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0506\n",
      "Iteration: 510/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0504\n",
      "Iteration: 511/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0503\n",
      "Iteration: 512/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0501\n",
      "Iteration: 513/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0500\n",
      "Iteration: 514/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0499\n",
      "Iteration: 515/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0497\n",
      "Iteration: 516/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0496\n",
      "Iteration: 517/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0495\n",
      "Iteration: 518/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0493\n",
      "Iteration: 519/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0492\n",
      "Iteration: 520/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0491\n",
      "Iteration: 521/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0489\n",
      "Iteration: 522/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0488\n",
      "Iteration: 523/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0487\n",
      "Iteration: 524/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0485\n",
      "Iteration: 525/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0484\n",
      "Iteration: 526/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0483\n",
      "Iteration: 527/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0482\n",
      "Iteration: 528/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0480\n",
      "Iteration: 529/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0479\n",
      "Iteration: 530/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0478\n",
      "Iteration: 531/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0477\n",
      "Iteration: 532/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0476\n",
      "Iteration: 533/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0475\n",
      "Iteration: 534/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0473\n",
      "Iteration: 535/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0472\n",
      "Iteration: 536/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0471\n",
      "Iteration: 537/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0470\n",
      "Iteration: 538/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0469\n",
      "Iteration: 539/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0468\n",
      "Iteration: 540/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0467\n",
      "Iteration: 541/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0466\n",
      "Iteration: 542/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0465\n",
      "Iteration: 543/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0464\n",
      "Iteration: 544/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0463\n",
      "Iteration: 545/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0462\n",
      "Iteration: 546/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0461\n",
      "Iteration: 547/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0460\n",
      "Iteration: 548/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0459\n",
      "Iteration: 549/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0458\n",
      "Iteration: 550/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0457\n",
      "Iteration: 551/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0456\n",
      "Iteration: 552/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0455\n",
      "Iteration: 553/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0455\n",
      "Iteration: 554/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0454\n",
      "Iteration: 555/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0453\n",
      "Iteration: 556/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0452\n",
      "Iteration: 557/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0451\n",
      "Iteration: 558/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0451\n",
      "Iteration: 559/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0450\n",
      "Iteration: 560/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0449\n",
      "Iteration: 561/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0449\n",
      "Iteration: 562/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0448\n",
      "Iteration: 563/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0447\n",
      "Iteration: 564/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0447\n",
      "Iteration: 565/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0446\n",
      "Iteration: 566/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0445\n",
      "Iteration: 567/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0445\n",
      "Iteration: 568/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0444\n",
      "Iteration: 569/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0444\n",
      "Iteration: 570/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0443\n",
      "Iteration: 571/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0443\n",
      "Iteration: 572/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 573/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 574/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 575/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 576/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 577/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 578/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 579/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 580/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 581/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 582/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 583/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 584/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 585/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 586/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 587/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 588/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 589/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 590/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 591/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 592/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 593/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 594/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 595/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 596/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 597/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 598/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 599/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 600/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 601/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 602/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 603/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 604/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 605/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 606/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 607/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0439\n",
      "Iteration: 608/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 609/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 610/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0440\n",
      "Iteration: 611/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 612/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 613/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 614/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 615/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 616/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0442\n",
      "Iteration: 617/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0444\n",
      "Iteration: 618/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0443\n",
      "Iteration: 619/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0445\n",
      "Iteration: 620/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0443\n",
      "Iteration: 621/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0447\n",
      "Iteration: 622/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0443\n",
      "Iteration: 623/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0450\n",
      "Iteration: 624/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 625/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0457\n",
      "Iteration: 626/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0436\n",
      "Iteration: 627/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0472\n",
      "Iteration: 628/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0425\n",
      "Iteration: 629/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0510\n",
      "Iteration: 630/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0423\n",
      "Iteration: 631/1000 \t Train Loss: 0.0049 \t Test Loss: 0.0587\n",
      "Iteration: 632/1000 \t Train Loss: 0.0053 \t Test Loss: 0.0573\n",
      "Iteration: 633/1000 \t Train Loss: 0.0065 \t Test Loss: 0.0549\n",
      "Iteration: 634/1000 \t Train Loss: 0.0065 \t Test Loss: 0.0659\n",
      "Iteration: 635/1000 \t Train Loss: 0.0061 \t Test Loss: 0.0417\n",
      "Iteration: 636/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0410\n",
      "Iteration: 637/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0503\n",
      "Iteration: 638/1000 \t Train Loss: 0.0055 \t Test Loss: 0.0525\n",
      "Iteration: 639/1000 \t Train Loss: 0.0059 \t Test Loss: 0.0545\n",
      "Iteration: 640/1000 \t Train Loss: 0.0057 \t Test Loss: 0.0400\n",
      "Iteration: 641/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0391\n",
      "Iteration: 642/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0458\n",
      "Iteration: 643/1000 \t Train Loss: 0.0051 \t Test Loss: 0.0428\n",
      "Iteration: 644/1000 \t Train Loss: 0.0051 \t Test Loss: 0.0415\n",
      "Iteration: 645/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0375\n",
      "Iteration: 646/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0441\n",
      "Iteration: 647/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0410\n",
      "Iteration: 648/1000 \t Train Loss: 0.0051 \t Test Loss: 0.0398\n",
      "Iteration: 649/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0375\n",
      "Iteration: 650/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0391\n",
      "Iteration: 651/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0442\n",
      "Iteration: 652/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0374\n",
      "Iteration: 653/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0375\n",
      "Iteration: 654/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0423\n",
      "Iteration: 655/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0374\n",
      "Iteration: 656/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0423\n",
      "Iteration: 657/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0386\n",
      "Iteration: 658/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0376\n",
      "Iteration: 659/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0429\n",
      "Iteration: 660/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0385\n",
      "Iteration: 661/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0403\n",
      "Iteration: 662/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0448\n",
      "Iteration: 663/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0385\n",
      "Iteration: 664/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0432\n",
      "Iteration: 665/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0413\n",
      "Iteration: 666/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0391\n",
      "Iteration: 667/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0426\n",
      "Iteration: 668/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0391\n",
      "Iteration: 669/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0401\n",
      "Iteration: 670/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0424\n",
      "Iteration: 671/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0393\n",
      "Iteration: 672/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0414\n",
      "Iteration: 673/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0403\n",
      "Iteration: 674/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0396\n",
      "Iteration: 675/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0423\n",
      "Iteration: 676/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0399\n",
      "Iteration: 677/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0407\n",
      "Iteration: 678/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0420\n",
      "Iteration: 679/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0403\n",
      "Iteration: 680/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0425\n",
      "Iteration: 681/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0410\n",
      "Iteration: 682/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0406\n",
      "Iteration: 683/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0425\n",
      "Iteration: 684/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0409\n",
      "Iteration: 685/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0423\n",
      "Iteration: 686/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0425\n",
      "Iteration: 687/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0415\n",
      "Iteration: 688/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0437\n",
      "Iteration: 689/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0423\n",
      "Iteration: 690/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0428\n",
      "Iteration: 691/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0436\n",
      "Iteration: 692/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0425\n",
      "Iteration: 693/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0446\n",
      "Iteration: 694/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0439\n",
      "Iteration: 695/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0440\n",
      "Iteration: 696/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0452\n",
      "Iteration: 697/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0440\n",
      "Iteration: 698/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0456\n",
      "Iteration: 699/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0450\n",
      "Iteration: 700/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0449\n",
      "Iteration: 701/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0461\n",
      "Iteration: 702/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0452\n",
      "Iteration: 703/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0465\n",
      "Iteration: 704/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0460\n",
      "Iteration: 705/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0459\n",
      "Iteration: 706/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0469\n",
      "Iteration: 707/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0462\n",
      "Iteration: 708/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0474\n",
      "Iteration: 709/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0471\n",
      "Iteration: 710/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0474\n",
      "Iteration: 711/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0481\n",
      "Iteration: 712/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0475\n",
      "Iteration: 713/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0485\n",
      "Iteration: 714/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0480\n",
      "Iteration: 715/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0485\n",
      "Iteration: 716/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0489\n",
      "Iteration: 717/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0486\n",
      "Iteration: 718/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0495\n",
      "Iteration: 719/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0490\n",
      "Iteration: 720/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0498\n",
      "Iteration: 721/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0497\n",
      "Iteration: 722/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0498\n",
      "Iteration: 723/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0504\n",
      "Iteration: 724/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0501\n",
      "Iteration: 725/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0509\n",
      "Iteration: 726/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0506\n",
      "Iteration: 727/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0511\n",
      "Iteration: 728/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0511\n",
      "Iteration: 729/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0512\n",
      "Iteration: 730/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0517\n",
      "Iteration: 731/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0515\n",
      "Iteration: 732/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0521\n",
      "Iteration: 733/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0518\n",
      "Iteration: 734/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0524\n",
      "Iteration: 735/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0522\n",
      "Iteration: 736/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0526\n",
      "Iteration: 737/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0526\n",
      "Iteration: 738/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0528\n",
      "Iteration: 739/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0532\n",
      "Iteration: 740/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0531\n",
      "Iteration: 741/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0535\n",
      "Iteration: 742/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0534\n",
      "Iteration: 743/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0539\n",
      "Iteration: 744/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0537\n",
      "Iteration: 745/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0542\n",
      "Iteration: 746/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 747/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0546\n",
      "Iteration: 748/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0544\n",
      "Iteration: 749/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0549\n",
      "Iteration: 750/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0546\n",
      "Iteration: 751/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0552\n",
      "Iteration: 752/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0549\n",
      "Iteration: 753/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0556\n",
      "Iteration: 754/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0551\n",
      "Iteration: 755/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0560\n",
      "Iteration: 756/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0552\n",
      "Iteration: 757/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0566\n",
      "Iteration: 758/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0552\n",
      "Iteration: 759/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0573\n",
      "Iteration: 760/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0548\n",
      "Iteration: 761/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0585\n",
      "Iteration: 762/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0537\n",
      "Iteration: 763/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0607\n",
      "Iteration: 764/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0514\n",
      "Iteration: 765/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0645\n",
      "Iteration: 766/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0471\n",
      "Iteration: 767/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0699\n",
      "Iteration: 768/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0432\n",
      "Iteration: 769/1000 \t Train Loss: 0.0052 \t Test Loss: 0.0680\n",
      "Iteration: 770/1000 \t Train Loss: 0.0053 \t Test Loss: 0.0425\n",
      "Iteration: 771/1000 \t Train Loss: 0.0052 \t Test Loss: 0.0539\n",
      "Iteration: 772/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0462\n",
      "Iteration: 773/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0454\n",
      "Iteration: 774/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0671\n",
      "Iteration: 775/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0418\n",
      "Iteration: 776/1000 \t Train Loss: 0.0054 \t Test Loss: 0.0623\n",
      "Iteration: 777/1000 \t Train Loss: 0.0053 \t Test Loss: 0.0407\n",
      "Iteration: 778/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0443\n",
      "Iteration: 779/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0537\n",
      "Iteration: 780/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0403\n",
      "Iteration: 781/1000 \t Train Loss: 0.0051 \t Test Loss: 0.0607\n",
      "Iteration: 782/1000 \t Train Loss: 0.0050 \t Test Loss: 0.0409\n",
      "Iteration: 783/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0451\n",
      "Iteration: 784/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0506\n",
      "Iteration: 785/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0399\n",
      "Iteration: 786/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0527\n",
      "Iteration: 787/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0450\n",
      "Iteration: 788/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0452\n",
      "Iteration: 789/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0581\n",
      "Iteration: 790/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0402\n",
      "Iteration: 791/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0471\n",
      "Iteration: 792/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0468\n",
      "Iteration: 793/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0425\n",
      "Iteration: 794/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0553\n",
      "Iteration: 795/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0424\n",
      "Iteration: 796/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0489\n",
      "Iteration: 797/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0522\n",
      "Iteration: 798/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0431\n",
      "Iteration: 799/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0507\n",
      "Iteration: 800/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0426\n",
      "Iteration: 801/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0454\n",
      "Iteration: 802/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0541\n",
      "Iteration: 803/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0432\n",
      "Iteration: 804/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0512\n",
      "Iteration: 805/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0461\n",
      "Iteration: 806/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0461\n",
      "Iteration: 807/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0535\n",
      "Iteration: 808/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0438\n",
      "Iteration: 809/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0497\n",
      "Iteration: 810/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0492\n",
      "Iteration: 811/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0475\n",
      "Iteration: 812/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 813/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0448\n",
      "Iteration: 814/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0499\n",
      "Iteration: 815/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0511\n",
      "Iteration: 816/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0482\n",
      "Iteration: 817/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0549\n",
      "Iteration: 818/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0473\n",
      "Iteration: 819/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0528\n",
      "Iteration: 820/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0530\n",
      "Iteration: 821/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0493\n",
      "Iteration: 822/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0538\n",
      "Iteration: 823/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0485\n",
      "Iteration: 824/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0541\n",
      "Iteration: 825/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0535\n",
      "Iteration: 826/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0511\n",
      "Iteration: 827/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0549\n",
      "Iteration: 828/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0504\n",
      "Iteration: 829/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0556\n",
      "Iteration: 830/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0528\n",
      "Iteration: 831/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0527\n",
      "Iteration: 832/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0552\n",
      "Iteration: 833/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0526\n",
      "Iteration: 834/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0569\n",
      "Iteration: 835/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0528\n",
      "Iteration: 836/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0550\n",
      "Iteration: 837/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0551\n",
      "Iteration: 838/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0549\n",
      "Iteration: 839/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0573\n",
      "Iteration: 840/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 841/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0575\n",
      "Iteration: 842/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0552\n",
      "Iteration: 843/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0572\n",
      "Iteration: 844/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0563\n",
      "Iteration: 845/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0563\n",
      "Iteration: 846/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0583\n",
      "Iteration: 847/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0566\n",
      "Iteration: 848/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0589\n",
      "Iteration: 849/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0561\n",
      "Iteration: 850/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0589\n",
      "Iteration: 851/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0574\n",
      "Iteration: 852/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0589\n",
      "Iteration: 853/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0581\n",
      "Iteration: 854/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0584\n",
      "Iteration: 855/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0592\n",
      "Iteration: 856/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0584\n",
      "Iteration: 857/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0597\n",
      "Iteration: 858/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0582\n",
      "Iteration: 859/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0605\n",
      "Iteration: 860/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0586\n",
      "Iteration: 861/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0608\n",
      "Iteration: 862/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0584\n",
      "Iteration: 863/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0610\n",
      "Iteration: 864/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0588\n",
      "Iteration: 865/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0615\n",
      "Iteration: 866/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0587\n",
      "Iteration: 867/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0619\n",
      "Iteration: 868/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0587\n",
      "Iteration: 869/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0626\n",
      "Iteration: 870/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0579\n",
      "Iteration: 871/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0634\n",
      "Iteration: 872/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0571\n",
      "Iteration: 873/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0653\n",
      "Iteration: 874/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0550\n",
      "Iteration: 875/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0676\n",
      "Iteration: 876/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0519\n",
      "Iteration: 877/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0708\n",
      "Iteration: 878/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0479\n",
      "Iteration: 879/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0717\n",
      "Iteration: 880/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0455\n",
      "Iteration: 881/1000 \t Train Loss: 0.0048 \t Test Loss: 0.0668\n",
      "Iteration: 882/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0463\n",
      "Iteration: 883/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0594\n",
      "Iteration: 884/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0536\n",
      "Iteration: 885/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0535\n",
      "Iteration: 886/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0634\n",
      "Iteration: 887/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0477\n",
      "Iteration: 888/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0672\n",
      "Iteration: 889/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0451\n",
      "Iteration: 890/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0619\n",
      "Iteration: 891/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0484\n",
      "Iteration: 892/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0545\n",
      "Iteration: 893/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0585\n",
      "Iteration: 894/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0487\n",
      "Iteration: 895/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0647\n",
      "Iteration: 896/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0460\n",
      "Iteration: 897/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0624\n",
      "Iteration: 898/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0469\n",
      "Iteration: 899/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0542\n",
      "Iteration: 900/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 901/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0482\n",
      "Iteration: 902/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0591\n",
      "Iteration: 903/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0461\n",
      "Iteration: 904/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0575\n",
      "Iteration: 905/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0491\n",
      "Iteration: 906/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0539\n",
      "Iteration: 907/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0546\n",
      "Iteration: 908/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0494\n",
      "Iteration: 909/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0583\n",
      "Iteration: 910/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0478\n",
      "Iteration: 911/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0575\n",
      "Iteration: 912/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0507\n",
      "Iteration: 913/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0558\n",
      "Iteration: 914/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0569\n",
      "Iteration: 915/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0526\n",
      "Iteration: 916/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0589\n",
      "Iteration: 917/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0497\n",
      "Iteration: 918/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0587\n",
      "Iteration: 919/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0505\n",
      "Iteration: 920/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0578\n",
      "Iteration: 921/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0538\n",
      "Iteration: 922/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0560\n",
      "Iteration: 923/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0565\n",
      "Iteration: 924/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0533\n",
      "Iteration: 925/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0583\n",
      "Iteration: 926/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0527\n",
      "Iteration: 927/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0600\n",
      "Iteration: 928/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0524\n",
      "Iteration: 929/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0600\n",
      "Iteration: 930/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0524\n",
      "Iteration: 931/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0600\n",
      "Iteration: 932/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0534\n",
      "Iteration: 933/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0604\n",
      "Iteration: 934/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0544\n",
      "Iteration: 935/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0603\n",
      "Iteration: 936/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0539\n",
      "Iteration: 937/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0599\n",
      "Iteration: 938/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0536\n",
      "Iteration: 939/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0610\n",
      "Iteration: 940/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0534\n",
      "Iteration: 941/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0624\n",
      "Iteration: 942/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0519\n",
      "Iteration: 943/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0641\n",
      "Iteration: 944/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0494\n",
      "Iteration: 945/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0661\n",
      "Iteration: 946/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0471\n",
      "Iteration: 947/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0668\n",
      "Iteration: 948/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0457\n",
      "Iteration: 949/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0633\n",
      "Iteration: 950/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0460\n",
      "Iteration: 951/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0583\n",
      "Iteration: 952/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0493\n",
      "Iteration: 953/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0539\n",
      "Iteration: 954/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0550\n",
      "Iteration: 955/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0502\n",
      "Iteration: 956/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0598\n",
      "Iteration: 957/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0475\n",
      "Iteration: 958/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0621\n",
      "Iteration: 959/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0469\n",
      "Iteration: 960/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0604\n",
      "Iteration: 961/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0486\n",
      "Iteration: 962/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0571\n",
      "Iteration: 963/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0523\n",
      "Iteration: 964/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 965/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0557\n",
      "Iteration: 966/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0507\n",
      "Iteration: 967/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0574\n",
      "Iteration: 968/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0484\n",
      "Iteration: 969/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0577\n",
      "Iteration: 970/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0486\n",
      "Iteration: 971/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0572\n",
      "Iteration: 972/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0506\n",
      "Iteration: 973/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0562\n",
      "Iteration: 974/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0526\n",
      "Iteration: 975/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0551\n",
      "Iteration: 976/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0542\n",
      "Iteration: 977/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0540\n",
      "Iteration: 978/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0560\n",
      "Iteration: 979/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0535\n",
      "Iteration: 980/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0582\n",
      "Iteration: 981/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0529\n",
      "Iteration: 982/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0601\n",
      "Iteration: 983/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0514\n",
      "Iteration: 984/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0622\n",
      "Iteration: 985/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0489\n",
      "Iteration: 986/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0644\n",
      "Iteration: 987/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0469\n",
      "Iteration: 988/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0647\n",
      "Iteration: 989/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0466\n",
      "Iteration: 990/1000 \t Train Loss: 0.0049 \t Test Loss: 0.0602\n",
      "Iteration: 991/1000 \t Train Loss: 0.0047 \t Test Loss: 0.0467\n",
      "Iteration: 992/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0545\n",
      "Iteration: 993/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0488\n",
      "Iteration: 994/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0507\n",
      "Iteration: 995/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0542\n",
      "Iteration: 996/1000 \t Train Loss: 0.0043 \t Test Loss: 0.0482\n",
      "Iteration: 997/1000 \t Train Loss: 0.0044 \t Test Loss: 0.0587\n",
      "Iteration: 998/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0473\n",
      "Iteration: 999/1000 \t Train Loss: 0.0046 \t Test Loss: 0.0587\n",
      "Iteration: 1000/1000 \t Train Loss: 0.0045 \t Test Loss: 0.0476\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_inputs=train_inputs,\n",
    "    train_targets=train_targets,\n",
    "    test_inputs=test_inputs,\n",
    "    test_targets=test_targets,\n",
    "    n_epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss per Iteration')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(test_losses, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss per Iteration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2502753a0e0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_targets.cpu())\n",
    "plt.plot(model(test_inputs).cpu().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_horizon(): \n",
    "    horizon_predictions = []\n",
    "    horizon_inputs = test_inputs[0]\n",
    "\n",
    "    while len(horizon_predictions) < len(test_targets):\n",
    "        prediction = model(horizon_inputs.view(1, T, -1))\n",
    "        \n",
    "        horizon_predictions.append(prediction.item())\n",
    "        horizon_inputs = torch.concat((horizon_inputs[1:], prediction))\n",
    "    \n",
    "    plt.plot(test_targets.cpu())  \n",
    "    plt.plot(horizon_predictions)\n",
    "\n",
    "plot_horizon() if X.shape == Y.shape else print('Unable to plot Horizon')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "862aaaa3bfdfe0cb3b02e12d68ad12f84f678ba56b93b757d8f1a9844b9ba170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
